{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2135ca-af01-47e6-9865-26959e6c410d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the example data\n",
    "week = 46\n",
    "month = 11\n",
    "monat = 'November'\n",
    "HotelName = 'Aparthotel Adagio Frankfurt City Messe'\n",
    "City = 'Frankfurt'\n",
    "Street = 'Hamburger Allee 4 '\n",
    "id = 1758394 # this is hotel_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3211db08-25df-4b42-abae-a49fb230444d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some Methods for filtering the JSON Data\n",
    "# JSON Data will contain customer data\n",
    "# The JSON Data will be loaded via API below\n",
    "def scoring(data):\n",
    "    score=data[\"average_score\"]\n",
    "    d_score = round((score/4)*10)\n",
    "    return d_score #score\n",
    "def dcheckin(data):\n",
    "    checkin = data[\"checkin\"]\n",
    "    d_checkin = datetime.strptime(checkin, \"%Y-%m-%d\").date()\n",
    "    return d_checkin #check-in date\n",
    "def dcheckout(data):\n",
    "    checkout = data[\"checkout\"]\n",
    "    d_checkout = datetime.strptime(checkout, \"%Y-%m-%d\").date()\n",
    "    return d_checkout\n",
    "def dnights(data):\n",
    "    d_nights = data[\"num_nights\"]\n",
    "    return d_nights #number of nights stayed\n",
    "def ddate(data):\n",
    "    date = data.split()[0]\n",
    "    d_date = datetime.strptime(date, \"%Y-%m-%d\").date()\n",
    "    return d_date #date when the review was written\n",
    "def dcount(data):\n",
    "    d_count_date=ddate(data[\"date\"])-dcheckout(data[\"stayed_room_info\"])\n",
    "    return d_count_date.days #days from checkout to reivew\n",
    "def custom_type(data):\n",
    "    d_customer_type=data\n",
    "    return d_customer_type #customer type\n",
    "def country(data):\n",
    "    d_country=data[\"countrycode\"]\n",
    "    return d_country # country\n",
    "def travel_purpose(data):\n",
    "    d_travel_purpose=data[\"travel_purpose\"]\n",
    "    return d_travel_purpose #travel purpose\n",
    "def room_name(data):\n",
    "    d_room_name = data[\"room_name\"]\n",
    "    return d_room_name #room name/category\n",
    "def positiv(data):\n",
    "    d_pro=data\n",
    "    return d_pro\n",
    "def negativ(data):\n",
    "    d_neg=data\n",
    "    return d_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210ff7b5-9df7-426f-b61d-f161187d6ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Al important Libraries and HTTP Header\n",
    "import http.client\n",
    "import json\n",
    "from datetime import datetime\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "conn = http.client.HTTPSConnection(\"booking-com15.p.rapidapi.com\")\n",
    "\n",
    "key = \"PUT HERE YOUR CODE\"\n",
    "\n",
    "headers = {\n",
    "    'x-rapidapi-key': key,\n",
    "    'x-rapidapi-host': \"booking-com15.p.rapidapi.com\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7214e1-74f3-4eb4-a5f7-a717fcb35bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch all customer data for november.2024 and october.2024\n",
    "# here for example we wanted only data from November and October\n",
    "# this was written in november.2024\n",
    "# thats why the condition is month-2\n",
    "# but the data can also contain older values,\n",
    "# since one batch of request comes with 25 customer reviews.\n",
    "response=[]\n",
    "i=1\n",
    "while True:\n",
    "    conn.request(\"GET\", \"/api/v1/hotels/getHotelReviews?hotel_id=\"+str(id)+\"&sort_option_id=sort_recent_desc&page_number=\"+str(i), headers=headers)\n",
    "    res = conn.getresponse()\n",
    "    data = res.read()\n",
    "    response.append(json.loads(data.decode(\"utf-8\")))\n",
    "    date = ddate(response[i-1][\"data\"][\"result\"][-1][\"date\"])\n",
    "    if date.month <= month-2: # this only interested in values oct and nov\n",
    "        break\n",
    "    else:\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38cca26-6784-4ad1-8dfb-8abaf60eb916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will start constructing a dataframe\n",
    "# for converting the JSON\n",
    "scores=[]\n",
    "checkin=[]\n",
    "checkout=[]\n",
    "nights=[]\n",
    "com_date=[]\n",
    "count_date=[]\n",
    "customer_type=[]\n",
    "d_country=[]\n",
    "trav_purpose=[]\n",
    "room_names=[]\n",
    "pos=[]\n",
    "neg=[]\n",
    "for i in range(len(response)):\n",
    "    for j in range(len(response[i][\"data\"][\"result\"])):\n",
    "        scores.append(scoring(response[i][\"data\"][\"result\"][j]))\n",
    "        checkin.append(dcheckin(response[i][\"data\"][\"result\"][j][\"stayed_room_info\"]))\n",
    "        checkout.append(dcheckout(response[i][\"data\"][\"result\"][j][\"stayed_room_info\"]))\n",
    "        nights.append(dnights(response[i][\"data\"][\"result\"][j][\"stayed_room_info\"]))\n",
    "        com_date.append(ddate(response[i][\"data\"][\"result\"][j][\"date\"]))\n",
    "        count_date.append(dcount(response[i][\"data\"][\"result\"][j]))\n",
    "        customer_type.append(custom_type(response[i][\"data\"][\"result\"][j][\"author\"][\"type_string\"]))\n",
    "        d_country.append(country(response[i][\"data\"][\"result\"][j][\"author\"]))\n",
    "        trav_purpose.append(travel_purpose(response[i][\"data\"][\"result\"][j]))\n",
    "        room_names.append(room_name(response[i][\"data\"][\"result\"][j][\"stayed_room_info\"]))\n",
    "        pos.append(positiv(response[i][\"data\"][\"result\"][j][\"pros\"]))\n",
    "        neg.append(positiv(response[i][\"data\"][\"result\"][j][\"cons\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988907d5-24d2-47fd-a38d-a1fff85734a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the dataframe\n",
    "df_1_base = {\n",
    "    'Score': scores,\n",
    "    'Check-In': checkin,\n",
    "    'Check-Out': checkout,\n",
    "    'Nights': nights,\n",
    "    'Comment_Date': com_date,\n",
    "    'Count_Date': count_date,\n",
    "    'Customer_Type': customer_type,\n",
    "    'Country': d_country,\n",
    "    'Travel_Purpose': trav_purpose,\n",
    "    'Room_Name': room_names,\n",
    "    'Positiv':pos,\n",
    "    'Negativ':neg\n",
    "}\n",
    "\n",
    "df_1 = pd.DataFrame(df_1_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab48081-5366-4ded-8b92-fb2e571f78d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the DataFrame as Hotel_ID\n",
    "df_1.to_excel('../'+str(id)+'/Hotel '+str(id)+'.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8db05b9-3902-491d-82ac-e43beef510ed",
   "metadata": {},
   "source": [
    "# OpenAI API Bewertung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba52e393-5ae1-4580-b096-2821f787d720",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load all important libraries for the GPT-3o sentiment analysis\n",
    "import http.client\n",
    "import json\n",
    "from datetime import datetime\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "from openai import OpenAI\n",
    "import re\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05cd08b-8ec0-42bd-82b9-53fca6c152c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the Hotel_ID.xlsx and safe as data_frame_1\n",
    "data_frame_1 = pd.read_excel('../'+str(id)+\"/Hotel \"+str(id)+\".xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c47a807-f23f-43c3-a77c-e5d3c57db4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subset of Data_Frame_1\n",
    "df_pos=data_frame_1[[\"Positiv\",\"Customer_Type\",\"Travel_Purpose\",\"Room_Name\",\"Comment_Date\"]].copy()\n",
    "df_neg=data_frame_1[[\"Negativ\",\"Customer_Type\",\"Travel_Purpose\",\"Room_Name\",\"Comment_Date\"]].copy()\n",
    "data_frame_1_new=data_frame_1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28521d2e-841a-4b5d-8224-2d9b54b66b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OPENAI_KEY\n",
    "OPENAI_API_KEY = Your_KEY #here comes openai api key\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c72a416-af29-4351-b430-220ab4a708a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Tag Classes for the sentiment analysis\n",
    "tags = \"Amenities (Entrance Area, Hotel Building etc.);Bar (Prices, Service, Beverages, Snacks etc.);Bathroom Cleanliness (Toilet, Shower,Towel,Bath etc.);Room Cleanliness (Bed, Furniture, Closet,Desk etc.);Comfort (Air Conditioning, Bed Size, Noise Level,Room Size, WiFi etc.);Food (Breakfast, Menu, Dinner etc.);Location (Distance to City Centre, Parking, Restaurants, Shopping, Sightseeing etc.);Wellness (Massage, Pool, Fitness, Sauna, etc.);Price;Service (Bar, Booking Process, Houskeeping, Reception etc.);Sonstiges (Alles was nicht zu den anderen Passt)\"\n",
    "#define the command for GPT-3o\n",
    "command = \"Evaluate the given sentence against the given categories and return a dictionary with the categories as keys and 1 for a match, 0 for no match. No line breaks in the answer. All categories need to be answered. Keys in double quotation mark.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e7e2a0-6eb1-40e5-b5ec-5347db18a7ac",
   "metadata": {},
   "source": [
    "## Positive Comment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc436686-80c4-4741-bdd3-9db77ffae258",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the comments in sentences and save them\n",
    "#in positive dataframe\n",
    "txt_pos=[]\n",
    "df_zw_pos=[]\n",
    "df_new_pos=[]\n",
    "#\n",
    "tag_pos_sonst=[]\n",
    "tag_pos_bad=[]\n",
    "tag_pos_room=[]\n",
    "tag_pos_amenities=[]\n",
    "tag_pos_bar=[]\n",
    "tag_pos_comfort=[]\n",
    "tag_pos_food=[]\n",
    "tag_pos_location=[]\n",
    "tag_pos_wellness=[]\n",
    "tag_pos_price=[]\n",
    "tag_pos_service=[]\n",
    "#\n",
    "df1_tag_pos_sonst=[]\n",
    "df1_tag_pos_bad=[]\n",
    "df1_tag_pos_room=[]\n",
    "df1_tag_pos_amenities=[]\n",
    "df1_tag_pos_bar=[]\n",
    "df1_tag_pos_comfort=[]\n",
    "df1_tag_pos_food=[]\n",
    "df1_tag_pos_location=[]\n",
    "df1_tag_pos_wellness=[]\n",
    "df1_tag_pos_price=[]\n",
    "df1_tag_pos_service=[]\n",
    "#\n",
    "for i in range(len(df_pos)):\n",
    "    txt_pos.append(re.split(r'(?<=[.!?,-]) +', str(df_pos[\"Positiv\"][i])))\n",
    "    for j in range(len(txt_pos[i])):\n",
    "        #print(txt_pos[i][j])<--only for testing\n",
    "        if (txt_pos[i][j] != 'nan'):\n",
    "            completion = client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages = [\n",
    "                {\"role\": \"system\", \"content\": \"You are a text classification assistant. Multiple Fits are possible. Answer please in a format unsing the categories as key and 1 for positive and 0 for negative. Dont use linebreaks in the answer.\"},\n",
    "                {\"role\": \"user\", \"content\": command+ \"Categories:\"+ tags+ \"Sentence:\" +str(txt_pos[i][j])}\n",
    "                ]\n",
    "            )\n",
    "            answer=(completion.choices[0].message.content)\n",
    "            #print(answer)<--only for testing\n",
    "            answer_json = json.loads(answer)\n",
    "            tag_pos_sonst.append(answer_json[\"Sonstiges\"])\n",
    "            tag_pos_amenities.append(answer_json[\"Amenities\"])\n",
    "            tag_pos_bar.append(answer_json[\"Bar\"])\n",
    "            tag_pos_room.append(answer_json[\"Room Cleanliness\"])\n",
    "            tag_pos_bad.append(answer_json[\"Bathroom Cleanliness\"])\n",
    "            tag_pos_comfort.append(answer_json[\"Comfort\"])\n",
    "            tag_pos_food.append(answer_json[\"Food\"])\n",
    "            tag_pos_location.append(answer_json[\"Location\"])\n",
    "            tag_pos_wellness.append(answer_json[\"Wellness\"])\n",
    "            tag_pos_price.append(answer_json[\"Price\"])\n",
    "            tag_pos_service.append(answer_json[\"Service\"])\n",
    "        else:\n",
    "            tag_pos_sonst.append(float('nan'))\n",
    "            tag_pos_amenities.append(float('nan'))\n",
    "            tag_pos_bar.append(float('nan'))\n",
    "            tag_pos_room.append(float('nan'))\n",
    "            tag_pos_bad.append(float('nan'))\n",
    "            tag_pos_comfort.append(float('nan'))\n",
    "            tag_pos_food.append(float('nan'))\n",
    "            tag_pos_location.append(float('nan'))\n",
    "            tag_pos_wellness.append(float('nan'))\n",
    "            tag_pos_price.append(float('nan'))\n",
    "            tag_pos_service.append(float('nan'))\n",
    "    df_zw_pos ={\n",
    "        'Positiv': txt_pos[i],\n",
    "        'Customer_Type': [df_pos.at[i,'Customer_Type']]*len(txt_pos[i]),\n",
    "        'Travel_Purpose': [df_pos.at[i,'Travel_Purpose']]*len(txt_pos[i]),\n",
    "        'Date': [df_pos.at[i,'Comment_Date']]*len(txt_pos[i]),\n",
    "        'Room_Name': [df_pos.at[i,'Room_Name']]*len(txt_pos[i]),\n",
    "        'Pos_Sonst': tag_pos_sonst,\n",
    "        'Pos_Bad':tag_pos_bad,\n",
    "        'Pos_Room':tag_pos_room,\n",
    "        'Pos_Amenities':tag_pos_amenities,\n",
    "        'Pos_Bar':tag_pos_bar,\n",
    "        'Pos_Comfort':tag_pos_comfort,\n",
    "        'Pos_Food':tag_pos_food,\n",
    "        'Pos_Location':tag_pos_location,\n",
    "        'Pos_Wellness':tag_pos_wellness,\n",
    "        'Pos_Price':tag_pos_price,\n",
    "        'Pos_Service':tag_pos_service\n",
    "    }\n",
    "    df1_tag_pos_sonst.append(max(tag_pos_sonst))\n",
    "    df1_tag_pos_bad.append(max(tag_pos_bad))\n",
    "    df1_tag_pos_room.append(max(tag_pos_room))\n",
    "    df1_tag_pos_amenities.append(max(tag_pos_amenities))\n",
    "    df1_tag_pos_bar.append(max(tag_pos_bar))\n",
    "    df1_tag_pos_comfort.append(max(tag_pos_comfort))\n",
    "    df1_tag_pos_food.append(max(tag_pos_food))\n",
    "    df1_tag_pos_location.append(max(tag_pos_location))\n",
    "    df1_tag_pos_wellness.append(max(tag_pos_wellness))\n",
    "    df1_tag_pos_price.append(max(tag_pos_price))\n",
    "    df1_tag_pos_service.append(max(tag_pos_service))\n",
    "    #create the list, which will be later the dataframe\n",
    "    df_new_pos.append(df_zw_pos)\n",
    "    #reset the values\n",
    "    tag_pos_sonst=[]\n",
    "    tag_pos_bad=[]\n",
    "    tag_pos_room=[]\n",
    "    tag_pos_amenities=[]\n",
    "    tag_pos_bar=[]\n",
    "    tag_pos_comfort=[]\n",
    "    tag_pos_food=[]\n",
    "    tag_pos_location=[]\n",
    "    tag_pos_wellness=[]\n",
    "    tag_pos_price=[]\n",
    "    tag_pos_service=[]\n",
    "#create from the list a dataframe\n",
    "df_new_pos_1 = pd.DataFrame(df_new_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541e5e92-d7ce-49de-b4fa-2493b2ef1e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flat the elements of the DataFrame\n",
    "df_new_pos_1 = df_new_pos_1.apply(lambda col: col.apply(lambda x: x[0] if isinstance(x, list) else x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ff8c85-52ed-40b4-8cfe-f02b96d54acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the new dataframe\n",
    "name='../'+str(id)+\"/Pos \"+str(id)\n",
    "df_new_pos_1.to_excel(name+\".xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6fb943-a7de-4d70-93b6-f190c36022c7",
   "metadata": {},
   "source": [
    "## Negative Comment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddf67b2-6cf4-4b1f-bfd9-1a516c5d33d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split comments in sentences and save in negative dataframe\n",
    "txt_neg=[]\n",
    "df_zw_neg=[]\n",
    "df_new_neg=[]\n",
    "#\n",
    "tag_neg_sonst=[]\n",
    "tag_neg_bad=[]\n",
    "tag_neg_room=[]\n",
    "tag_neg_amenities=[]\n",
    "tag_neg_bar=[]\n",
    "tag_neg_comfort=[]\n",
    "tag_neg_food=[]\n",
    "tag_neg_location=[]\n",
    "tag_neg_wellness=[]\n",
    "tag_neg_price=[]\n",
    "tag_neg_service=[]\n",
    "#\n",
    "df1_tag_neg_sonst=[]\n",
    "df1_tag_neg_bad=[]\n",
    "df1_tag_neg_room=[]\n",
    "df1_tag_neg_amenities=[]\n",
    "df1_tag_neg_bar=[]\n",
    "df1_tag_neg_comfort=[]\n",
    "df1_tag_neg_food=[]\n",
    "df1_tag_neg_location=[]\n",
    "df1_tag_neg_wellness=[]\n",
    "df1_tag_neg_price=[]\n",
    "df1_tag_neg_service=[]\n",
    "#\n",
    "for i in range(len(df_neg)):\n",
    "    txt_neg.append(re.split(r'(?<=[.!?,-]) +', str(df_neg[\"Negativ\"][i])))\n",
    "    for j in range(len(txt_neg[i])):\n",
    "        #print(txt_pos[i][j])\n",
    "        if (txt_neg[i][j] != 'nan'):\n",
    "            completion = client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages = [\n",
    "                {\"role\": \"system\", \"content\": \"You are a text classification assistant. Multiple Fits are possible. Answer please in a format unsing the categories as key and 1 for positive and 0 for negative. Dont use linebreaks in the answer.\"},\n",
    "                {\"role\": \"user\", \"content\": command+ \"Categories:\"+ tags+ \"Sentence:\" +str(txt_neg[i][j])}\n",
    "                ]\n",
    "            )\n",
    "            answer=(completion.choices[0].message.content)\n",
    "            #print(answer)\n",
    "            answer_json = json.loads(answer)\n",
    "            tag_neg_sonst.append(answer_json[\"Sonstiges\"])\n",
    "            tag_neg_amenities.append(answer_json[\"Amenities\"])\n",
    "            tag_neg_bar.append(answer_json[\"Bar\"])\n",
    "            tag_neg_room.append(answer_json[\"Room Cleanliness\"])\n",
    "            tag_neg_bad.append(answer_json[\"Bathroom Cleanliness\"])\n",
    "            tag_neg_comfort.append(answer_json[\"Comfort\"])\n",
    "            tag_neg_food.append(answer_json[\"Food\"])\n",
    "            tag_neg_location.append(answer_json[\"Location\"])\n",
    "            tag_neg_wellness.append(answer_json[\"Wellness\"])\n",
    "            tag_neg_price.append(answer_json[\"Price\"])\n",
    "            tag_neg_service.append(answer_json[\"Service\"])\n",
    "        else:\n",
    "            tag_neg_sonst.append(float('nan'))\n",
    "            tag_neg_amenities.append(float('nan'))\n",
    "            tag_neg_bar.append(float('nan'))\n",
    "            tag_neg_room.append(float('nan'))\n",
    "            tag_neg_bad.append(float('nan'))\n",
    "            tag_neg_comfort.append(float('nan'))\n",
    "            tag_neg_food.append(float('nan'))\n",
    "            tag_neg_location.append(float('nan'))\n",
    "            tag_neg_wellness.append(float('nan'))\n",
    "            tag_neg_price.append(float('nan'))\n",
    "            tag_neg_service.append(float('nan'))\n",
    "    df_zw_neg ={\n",
    "        'Negativ': txt_neg[i],\n",
    "        'Customer_Type': [df_neg.at[i,'Customer_Type']]*len(txt_neg[i]),\n",
    "        'Travel_Purpose': [df_neg.at[i,'Travel_Purpose']]*len(txt_neg[i]),\n",
    "        'Date': [df_neg.at[i,'Comment_Date']]*len(txt_neg[i]),\n",
    "        'Room_Name': [df_neg.at[i,'Room_Name']]*len(txt_neg[i]),\n",
    "        'Neg_Sonst': tag_neg_sonst,\n",
    "        'Neg_Bad':tag_neg_bad,\n",
    "        'Neg_Room':tag_neg_room,\n",
    "        'Neg_Amenities':tag_neg_amenities,\n",
    "        'Neg_Bar':tag_neg_bar,\n",
    "        'Neg_Comfort':tag_neg_comfort,\n",
    "        'Neg_Food':tag_neg_food,\n",
    "        'Neg_Location':tag_neg_location,\n",
    "        'Neg_Wellness':tag_neg_wellness,\n",
    "        'Neg_Price':tag_neg_price,\n",
    "        'Neg_Service':tag_neg_service\n",
    "    }\n",
    "    df1_tag_neg_sonst.append(max(tag_neg_sonst))\n",
    "    df1_tag_neg_bad.append(max(tag_neg_bad))\n",
    "    df1_tag_neg_room.append(max(tag_neg_room))\n",
    "    df1_tag_neg_amenities.append(max(tag_neg_amenities))\n",
    "    df1_tag_neg_bar.append(max(tag_neg_bar))\n",
    "    df1_tag_neg_comfort.append(max(tag_neg_comfort))\n",
    "    df1_tag_neg_food.append(max(tag_neg_food))\n",
    "    df1_tag_neg_location.append(max(tag_neg_location))\n",
    "    df1_tag_neg_wellness.append(max(tag_neg_wellness))\n",
    "    df1_tag_neg_price.append(max(tag_neg_price))\n",
    "    df1_tag_neg_service.append(max(tag_neg_service))\n",
    "    #create the list, which will be later the dataframe\n",
    "    df_new_neg.append(df_zw_neg)\n",
    "    #reset the values\n",
    "    tag_neg_sonst=[]\n",
    "    tag_neg_bad=[]\n",
    "    tag_neg_room=[]\n",
    "    tag_neg_amenities=[]\n",
    "    tag_neg_bar=[]\n",
    "    tag_neg_comfort=[]\n",
    "    tag_neg_food=[]\n",
    "    tag_neg_location=[]\n",
    "    tag_neg_wellness=[]\n",
    "    tag_neg_price=[]\n",
    "    tag_neg_service=[]\n",
    "#create a dataframe from the list\n",
    "df_new_neg_1 = pd.DataFrame(df_new_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45064ea-3439-4cf0-ab9b-f3617d1877d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flat the elements of the dataframe\n",
    "df_new_neg_1 = df_new_neg_1.apply(lambda col: col.apply(lambda x: x[0] if isinstance(x, list) else x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4c1220-a5ac-496b-acf9-e59c42e7aa34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframe\n",
    "name='../'+(id)+\"/Neg \"+str(id)\n",
    "df_new_neg_1.to_excel(name+\".xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0450b4bd-5b75-402c-bc2c-af1f99e9f937",
   "metadata": {},
   "source": [
    "## Generate a General.xlsx including the tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10275b14-6a36-4a04-82ce-031a3d347332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the tags to a general dataframe\n",
    "data_frame_1_new[\"Neg_Sonst\"]=df1_tag_neg_sonst\n",
    "data_frame_1_new[\"Neg_Bad\"]=df1_tag_neg_bad\n",
    "data_frame_1_new[\"Neg_Room\"]=df1_tag_neg_room\n",
    "data_frame_1_new[\"Neg_Amenities\"]=df1_tag_neg_amenities\n",
    "data_frame_1_new[\"Neg_Bar\"]=df1_tag_neg_bar\n",
    "data_frame_1_new[\"Neg_Comfort\"]=df1_tag_neg_comfort\n",
    "data_frame_1_new[\"Neg_Food\"]=df1_tag_neg_food\n",
    "data_frame_1_new[\"Neg_Location\"]=df1_tag_neg_location\n",
    "data_frame_1_new[\"Neg_Wellness\"]=df1_tag_neg_wellness\n",
    "data_frame_1_new[\"Neg_Price\"]=df1_tag_neg_price\n",
    "data_frame_1_new[\"Neg_Service\"]=df1_tag_neg_service\n",
    "data_frame_1_new[\"Pos_Sonst\"]=df1_tag_pos_sonst\n",
    "data_frame_1_new[\"Pos_Bad\"]=df1_tag_pos_bad\n",
    "data_frame_1_new[\"Pos_Room\"]=df1_tag_pos_room\n",
    "data_frame_1_new[\"Pos_Amenities\"]=df1_tag_pos_amenities\n",
    "data_frame_1_new[\"Pos_Bar\"]=df1_tag_pos_bar\n",
    "data_frame_1_new[\"Pos_Comfort\"]=df1_tag_pos_comfort\n",
    "data_frame_1_new[\"Pos_Food\"]=df1_tag_pos_food\n",
    "data_frame_1_new[\"Pos_Location\"]=df1_tag_pos_location\n",
    "data_frame_1_new[\"Pos_Wellness\"]=df1_tag_pos_wellness\n",
    "data_frame_1_new[\"Pos_Price\"]=df1_tag_pos_price\n",
    "data_frame_1_new[\"Pos_Service\"]=df1_tag_pos_service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2004138a-b5b1-4db0-b10b-43d17a3039c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# safe the dataframe\n",
    "name='../'+str(id)+\"/General \"+str(id)\n",
    "data_frame_1_new.to_excel(name+\".xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
